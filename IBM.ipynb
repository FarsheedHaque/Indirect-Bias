{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc15d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup,AdamW\n",
    "from transformers import BertTokenizer,BertForSequenceClassification,BertConfig\n",
    "from transformers import DistilBertTokenizer,DistilBertForSequenceClassification,DistilBertConfig\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function for formatting time\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d15fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_parity(label, sensitive_att):\n",
    "\n",
    "  m1,m0,f1,f0 = 0,0,0,0\n",
    "\n",
    "  for i in range(len(label)):\n",
    "    if label[i] == 1 and sensitive_att[i]== 1:\n",
    "      m1 = m1 +1\n",
    "\n",
    "    if label[i] == 0 and sensitive_att[i]== 1:\n",
    "      m0 = m0 +1\n",
    "\n",
    "    if label[i] == 1 and sensitive_att[i]== 0:\n",
    "      f1 = f1 +1\n",
    "\n",
    "    if label[i] == 0 and sensitive_att[i]== 0:\n",
    "      f0 = f0 +1\n",
    "\n",
    "  rd = abs((m1/(m1+m0)) - (f1/(f1+f0)))\n",
    "\n",
    "  return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c75ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Device used for training\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('review/train.csv')\n",
    "test_df = pd.read_csv('review/test.csv')\n",
    "\n",
    "train_post,val_post,train_label,val_label,train_gender,val_gender = train_test_split(\n",
    "    main_df.text.values.tolist(),\n",
    "    main_df.label.values.tolist(),\n",
    "    main_df.gender.values.tolist(),\n",
    "    test_size=0.10,random_state=42)\n",
    "\n",
    "test_posts = test_df.text.values.tolist()\n",
    "test_label = test_df.label.values.tolist()\n",
    "test_gender = test_df.gender.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d385c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crosstab = pd.crosstab(train_gender,\n",
    "                            train_label,\n",
    "                               margins = True)\n",
    "\n",
    "print(train_crosstab)\n",
    "print(\"\\nTrain DP:\")\n",
    "print(abs((train_crosstab[1][0]/(train_crosstab[1][0] + train_crosstab[0][0])) - train_crosstab[1][1]/(train_crosstab[0][1]+train_crosstab[1][1])))\n",
    "\n",
    "\n",
    "val_crosstab = pd.crosstab(val_gender,\n",
    "                            val_label,\n",
    "                               margins = True)\n",
    "\n",
    "print(val_crosstab)\n",
    "print(\"\\nValidation DP:\")\n",
    "print(abs((val_crosstab[1][0]/(val_crosstab[1][0] + val_crosstab[0][0])) - val_crosstab[1][1]/(val_crosstab[0][1]+val_crosstab[1][1])))\n",
    "\n",
    "\n",
    "\n",
    "test_crosstab = pd.crosstab(test_gender,\n",
    "                            test_label,\n",
    "                               margins = True)\n",
    "\n",
    "print(test_crosstab)\n",
    "print(\"\\nTest DP:\")\n",
    "print(abs((test_crosstab[1][0]/(test_crosstab[1][0] + test_crosstab[0][0])) - test_crosstab[1][1]/(test_crosstab[0][1]+test_crosstab[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing hyperparmaters\n",
    "batch_size = 50\n",
    "learning_rate = 0.00001\n",
    "learning_rate_adv = 0.0001\n",
    "epochs = 5 \n",
    "MAX_LEN = 256\n",
    "\n",
    "epsilon = 1e-8\n",
    "warmup_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88bf991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_util(given_text,MAX_LEN):\n",
    "  input_ids=[]\n",
    "  attention_masks=[]\n",
    "  #Tokenizing the posts,adding special tokens,truncating and creating the attention masks\n",
    "  for post in given_text:\n",
    "    # print (post)\n",
    "    # print (type(post))\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        post,                      # Sentence to encode.\n",
    "                        add_special_tokens = True,\n",
    "                        truncation = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                        # is_split_into_words=True\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "  #Converting the lists into tensors\n",
    "  input_ids = torch.cat(input_ids, dim=0)\n",
    "  attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "  return input_ids,attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the training dataset and gathering the input ID's of each token,attention masks\n",
    "trn_inputs,trn_attentions = tokenize_util(train_post,MAX_LEN)\n",
    "train_label = torch.tensor(train_label)\n",
    "train_sensitive = torch.tensor(train_gender)\n",
    "\n",
    "#Tokenizing the validation dataset and gathering the input ID's of each token,attention masks\n",
    "vldtn_inputs,vldtn_attentions = tokenize_util(val_post,MAX_LEN)\n",
    "val_label = torch.tensor(val_label)\n",
    "val_sensitive = torch.tensor(val_gender)\n",
    "\n",
    "#Tokenizing the training dataset and gathering the input ID's of each token,attention masks\n",
    "test_inputs,test_attentions=tokenize_util(test_posts,MAX_LEN)\n",
    "test_label = torch.tensor(test_label)\n",
    "test_sensitive = torch.tensor(test_gender)\n",
    "\n",
    "print(np.asarray(trn_inputs).shape, np.asarray(trn_attentions).shape, np.asarray(train_label).shape)\n",
    "print(np.asarray(vldtn_inputs).shape, np.asarray(vldtn_attentions).shape, np.asarray(val_label).shape)\n",
    "print(np.asarray(test_inputs).shape, np.asarray(test_attentions).shape, np.asarray(test_label).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining training input ID's,attention masks and labels into TensorDatasets\n",
    "train_dataset = TensorDataset(trn_inputs,trn_attentions,train_label,train_sensitive)\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "val_dataset = TensorDataset(vldtn_inputs, vldtn_attentions,val_label,val_sensitive)\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "test_dataset = TensorDataset(test_inputs, test_attentions,test_label,test_sensitive)\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8526bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DistilBertForSequenceClassification.from_pretrained(\n",
    "\n",
    "    bert_model, # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.\n",
    "    output_attentions = True, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "clf.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37cb41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv = nn.Sequential(\n",
    "    nn.Linear(768, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 2),\n",
    ")\n",
    "adv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c808bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dir = 'review/models/distilbert/vanila/model_g'\n",
    "tokenizer_g = DistilBertTokenizer.from_pretrained(g_dir)\n",
    "g = DistilBertForSequenceClassification.from_pretrained(g_dir, num_labels = 2, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdcfc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(clf.parameters(),\n",
    "              lr=learning_rate,\n",
    "              eps = epsilon)\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "adv_optim = AdamW(adv.parameters(),\n",
    "                            lr=learning_rate_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,data):\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  preds=[]\n",
    "  labels=[]\n",
    "  sensitives=[]\n",
    "  total_eval_loss = 0\n",
    "\n",
    "  for batch in data:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_sensitive = batch[3].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model( b_input_ids,\n",
    "#                              token_type_ids=None,\n",
    "                             attention_mask=b_input_mask,\n",
    "                             labels=b_labels, output_attentions=True)\n",
    "\n",
    "        loss,logits = outputs.loss,outputs.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        sensitive_ids = b_sensitive.to('cpu').numpy()\n",
    "        preds.append(logits)\n",
    "        labels.append(label_ids)\n",
    "        sensitives.append(sensitive_ids)\n",
    "        total_eval_loss += loss.item()\n",
    "        \n",
    "  preds = np.concatenate(preds,axis=0)\n",
    "  preds = np.argmax(preds, axis=1).flatten()  \n",
    "  labels = np.concatenate(labels,axis=0)\n",
    "  labels = labels.flatten()\n",
    "  sensitives = np.concatenate(sensitives,axis=0)\n",
    "  sensitives = sensitives.flatten()\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  rd = demographic_parity(preds, sensitives)\n",
    "\n",
    "  return acc, rd, total_eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Function to mask stop words and punctuation in attention matrices\n",
    "def mask_preprocessing(attention_tuple, input_ids, tokenizer):\n",
    "    masked_attention_layers = []\n",
    "    for attention in attention_tuple:\n",
    "        masked_attention = attention.clone()\n",
    "        for i, seq in enumerate(input_ids):\n",
    "            for j, token_id in enumerate(seq):\n",
    "                token = tokenizer.decode([token_id])\n",
    "                if token in stop_words or token in punctuation:\n",
    "                    masked_attention[i, :, j, :] = 0\n",
    "                    masked_attention[i, :, :, j] = 0\n",
    "        masked_attention_layers.append(masked_attention)\n",
    "    return tuple(masked_attention_layers)\n",
    "\n",
    "\n",
    "def min_max_normalize(attention):\n",
    "    min_val = torch.min(attention)\n",
    "    max_val = torch.max(attention)\n",
    "    normalized_attention = (attention - min_val) / (max_val - min_val)\n",
    "    return normalized_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec5d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_model(clf, data, optimizer, scheduler, epoch):\n",
    "  clf.train()\n",
    "\n",
    "  for e in range(epoch):\n",
    "    print(\"\")\n",
    "    print('epoch: ', e+1)\n",
    "    epoch_loss = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for step, batch in enumerate(data):\n",
    "\n",
    "      if step % 100 == 0 and not step == 0:\n",
    "          # Calculate elapsed time in minutes.\n",
    "          elapsed = format_time(time.time() - t0)\n",
    "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "      b_input_ids = batch[0].to(device)\n",
    "      b_input_mask = batch[1].to(device)\n",
    "      b_labels = batch[2].to(device)\n",
    "\n",
    "      inputs = {'input_ids':      b_input_ids,\n",
    "                'attention_mask': b_input_mask,\n",
    "                'labels':         b_labels,\n",
    "                }\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      outputs = clf(**inputs)\n",
    "      loss = outputs[0]\n",
    "      logits = outputs.logits\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "      preds.append(logits)\n",
    "      labels.append(label_ids)\n",
    "      epoch_loss += loss.item()\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(clf.parameters(), 1.0)\n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "        \n",
    "    print(\"loss: {0:.7f}\".format(epoch_loss/len(data)))\n",
    "    preds = np.concatenate(preds,axis=0)\n",
    "    preds = np.argmax(preds, axis=1).flatten()  \n",
    "    labels = np.concatenate(labels,axis=0)\n",
    "    labels = labels.flatten()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1_micro = f1_score(labels, preds, average=\"micro\")\n",
    "    print(\"accuracy: {0:.7f}\".format(acc))\n",
    "    print(\"f1: {0:.7f}\".format(f1_micro))\n",
    "\n",
    "  return clf\n",
    "\n",
    "\n",
    "def pretrain_debiasing_model(adv, clf, data, adv_optimizer, epoch):\n",
    "  cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "#   cross_entropy_loss = torch.nn.BCEWithLogitsLoss()\n",
    "  adv.train()\n",
    "\n",
    "  for e in range(epoch):\n",
    "    print(\"\")\n",
    "    print('epoch: ', e+1)\n",
    "    epoch_loss = 0\n",
    "    preds = []\n",
    "    sensitives = []\n",
    "    t0 = time.time()\n",
    "\n",
    "    for step, batch in enumerate(data):\n",
    "\n",
    "      if step % 100 == 0 and not step == 0:\n",
    "          # Calculate elapsed time in minutes.\n",
    "          elapsed = format_time(time.time() - t0)\n",
    "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "      b_input_ids = batch[0].to(device)\n",
    "      b_input_mask = batch[1].to(device)\n",
    "      b_labels = batch[2].to(device)\n",
    "      b_sensitive = batch[3].to(device)\n",
    "\n",
    "      inputs = {'input_ids':      b_input_ids,\n",
    "                'attention_mask': b_input_mask,\n",
    "                'labels':         b_labels,\n",
    "                }\n",
    "    \n",
    "      adv_optimizer.zero_grad()\n",
    "      outputs = clf(**inputs)\n",
    "      last_hidden_states = outputs.hidden_states[-1][:, 0, :] \n",
    "      adv_outputs = adv(last_hidden_states)\n",
    "      p = adv_outputs.detach().cpu().numpy()\n",
    "      preds.append(p) \n",
    "      adv_loss = cross_entropy_loss(adv_outputs, b_sensitive)\n",
    "      sensitive_ids = b_sensitive.to('cpu').numpy()\n",
    "      sensitives.append(sensitive_ids)\n",
    "      epoch_loss += adv_loss.item()\n",
    "      adv_loss.backward()\n",
    "      adv_optimizer.step()\n",
    "\n",
    "    print(\"loss: {0:.7f}\".format(epoch_loss/len(data)))\n",
    "    preds = np.concatenate(preds,axis=0)\n",
    "    preds = np.argmax(preds, axis=1).flatten() \n",
    "    sensitives = np.concatenate(sensitives,axis=0)\n",
    "    sensitives = sensitives.flatten()\n",
    "    acc = accuracy_score(sensitives, preds)\n",
    "    f1_micro = f1_score(sensitives, preds, average=\"micro\")\n",
    "    print(\"accuracy: {0:.7f}\".format(acc))\n",
    "    print(\"f1: {0:.7f}\".format(f1_micro))\n",
    "\n",
    "  return adv\n",
    "\n",
    "\n",
    "def evaluate_to_attention(model, b_input_ids, attention_mask):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=attention_mask, output_attentions=True)\n",
    "\n",
    "    attention = outputs.attentions\n",
    "\n",
    "    return attention\n",
    "\n",
    "\n",
    "def train_model(clf, g, adv, data, optimizer, adv_optimizer, lmbda, alpha):\n",
    "  cross_entropy_loss = torch.nn.CrossEntropyLoss()  \n",
    "  epoch_loss = 0\n",
    "  preds = []\n",
    "  labels = []\n",
    "  sensitives=[]\n",
    "  clf.train()\n",
    "    \n",
    "  g.to(device)\n",
    "\n",
    "  for step, batch in enumerate(data):\n",
    "\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    b_sensitive = batch[3].to(device)\n",
    "\n",
    "    inputs = {'input_ids':      b_input_ids,\n",
    "              'attention_mask': b_input_mask,\n",
    "              'labels':         b_labels,\n",
    "              }\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = clf(**inputs)\n",
    "    loss = outputs[0]\n",
    "    logits = outputs.logits\n",
    "    last_hidden_states = outputs.hidden_states[-1][:, 0, :]\n",
    "    \n",
    "    f_attention = outputs.attentions\n",
    "    g_attention= evaluate_to_attention(g, b_input_ids, b_input_mask)\n",
    "    \n",
    "    # Mask stop words and punctuation in attention matrices\n",
    "    f_attention_masked = mask_preprocessing(f_attention, b_input_ids, tokenizer)\n",
    "    g_attention_masked = mask_preprocessing(g_attention, b_input_ids, tokenizer)\n",
    "    \n",
    "    f_attention_stacked = torch.stack(f_attention_masked)\n",
    "    g_attention_stacked = torch.stack(g_attention_masked)\n",
    "\n",
    "    # Compute the mean across the layer dimension (0th dimension after stacking)\n",
    "    f_attention_aggregated = torch.mean(f_attention_stacked, dim=0)\n",
    "    g_attention_aggregated = torch.mean(g_attention_stacked, dim=0)\n",
    "\n",
    "    # Reshape the aggregated attention matrices\n",
    "    f_attention_aggregated = f_attention_aggregated.view(-1, f_attention_aggregated.size(-2), f_attention_aggregated.size(-1))\n",
    "    g_attention_aggregated = g_attention_aggregated.view(-1, g_attention_aggregated.size(-2), g_attention_aggregated.size(-1))\n",
    "    \n",
    "    f_attention_normalized = min_max_normalize(f_attention_aggregated)\n",
    "    g_attention_normalized = min_max_normalize(g_attention_aggregated)\n",
    "\n",
    "    # Compute the cosine similarity for the aggregated attention\n",
    "    cosine_similarity_aggregated = F.cosine_similarity(f_attention_normalized, g_attention_normalized, dim=-1)\n",
    "    cosine_similarity_aggregated = cosine_similarity_aggregated*cosine_similarity_aggregated    \n",
    "    mean_cosine_similarity = cosine_similarity_aggregated.mean()\n",
    "    \n",
    "    p = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    sensitive_ids = b_sensitive.to('cpu').numpy()\n",
    "    preds.append(p)\n",
    "    labels.append(label_ids)\n",
    "    sensitives.append(sensitive_ids)\n",
    "    adv_outputs = adv(last_hidden_states)\n",
    "    adv_loss = cross_entropy_loss(adv_outputs, b_sensitive)\n",
    "    total_loss = loss - (lmbda * adv_loss) + (alpha * mean_cosine_similarity)\n",
    "#     total_loss = loss + (alpha * mean_cosine_similarity)\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(\"clf loss: {0:.7f}\".format(loss.item()))\n",
    "    print(\"adv loss: {0:.7f}\".format(adv_loss.item()))\n",
    "    print(\"cosine similarity: {0:.7f}\".format(mean_cosine_similarity))\n",
    "    print(\"total loss: {0:.7f}\".format(total_loss.item()))\n",
    "    preds = np.concatenate(preds,axis=0)\n",
    "    preds = np.argmax(preds, axis=1).flatten()  \n",
    "    labels = np.concatenate(labels,axis=0)\n",
    "    labels = labels.flatten()\n",
    "    sensitives = np.concatenate(sensitives,axis=0)\n",
    "    sensitives = sensitives.flatten()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1_micro = f1_score(labels, preds, average=\"micro\")\n",
    "    print(\"accuracy: {0:.7f}\".format(acc))\n",
    "    print(\"f1: {0:.7f}\".format(f1_micro))\n",
    "    \n",
    "    break\n",
    "\n",
    "  return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a9876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"~~~~~~~~~~~~~~~ CLF Pre-training ~~~~~~~~~~~~~~~\")\n",
    "for param in adv.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "clf = pretrain_model(clf, train_dataloader, optim, scheduler, 3)\n",
    "\n",
    "for param in adv.parameters():\n",
    "    param.requires_grad = True\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1555f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"~~~~~~~~~~~~~~~ ADV Pre-training ~~~~~~~~~~~~~~~\")\n",
    "for param in clf.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "adv = pretrain_debiasing_model(adv, clf, train_dataloader, adv_optim, 25)\n",
    "\n",
    "for param in clf.parameters():\n",
    "    param.requires_grad = True\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1775e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 40\n",
    "lbda = 10\n",
    "alpha = 5\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    print(\"\\n\")\n",
    "    print(\"Iteration: \", iteration)\n",
    "    \n",
    "    #train adv for one epoch\n",
    "    for param in clf.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    print(\"-------------for adv-------------\")\n",
    "    adv = pretrain_debiasing_model(adv, clf, train_dataloader, adv_optim, 1)\n",
    "\n",
    "    for param in clf.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    #train clf for one mini-batch\n",
    "    for param in adv.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"-------------for clf-------------\")\n",
    "    clf = train_model(clf, g, adv, train_dataloader, optim, adv_optim, lbda, alpha)\n",
    "\n",
    "    for param in adv.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    if (iteration + 1) % 2 == 0:\n",
    "        print(\"\\n\")\n",
    "        print(\"evaluation\\n\")\n",
    "        acc, rd, lss = evaluate(clf, train_dataloader)\n",
    "        print(\"train loss: {0:.7f}\".format(lss))\n",
    "        print(\"train accuracy: {0:.7f}\".format(acc))\n",
    "#         print(\"train F1: {0:.2f}\".format(f1))\n",
    "        print(\"train E-Opp: {0:.7f}\".format(rd))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        acc, rd, lss = evaluate(clf, validation_dataloader)\n",
    "        print(\"validation loss: {0:.7f}\".format(lss))\n",
    "        print(\"validation accuracy: {0:.7f}\".format(acc))\n",
    "#         print(\"validation f1: {0:.2f}\".format(f1))\n",
    "        print(\"validation E-Opp: {0:.7f}\".format(rd))\n",
    "        \n",
    "print(\"\\n\")\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ce78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, rd, lss = evaluate(clf, test_dataloader)\n",
    "print(acc, rd, lss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
